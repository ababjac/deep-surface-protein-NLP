{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd483e19-9440-45ee-a195-0bc338b70049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 11:30:26.036855: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-05 11:30:27.193710: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-05 11:30:29.392268: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /spack/spack-0.17.1/apps/linux-rhel8-cascadelake/gcc-10.2.0/python-3.9.10-y63csltfuw5dhi5qffpdm4zmmfupfkqg/lib\n",
      "2023-04-05 11:30:29.392857: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /spack/spack-0.17.1/apps/linux-rhel8-cascadelake/gcc-10.2.0/python-3.9.10-y63csltfuw5dhi5qffpdm4zmmfupfkqg/lib\n",
      "2023-04-05 11:30:29.392865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a451aaf5-0abc-451b-90b1-3dddecd0d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/lustre/isaac/proj/UTK0196/deep-surface-protein-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd93717-121f-471c-ad18-7f6182704c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Tells the model we need to use the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25bba8d-0f89-480b-b95b-1e503aa55a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH+'M0059E_training_set.tsv', delimiter=',', header=0, nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b914c9-d5d7-48d4-b25a-3fb5e1ad0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(115000, random_state=1097253) #random set\n",
    "#df = df[(df['percent.identity'] >= 74.5) & (df['percent.identity'] < 89.6)] #middle set\n",
    "#df = df[(df['percent.identity'] >= 89.6) | (df['percent.identity'] < 74.5)] #edge set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99c30ca-e632-46f0-8a60-d19dbcbb9a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['deep.ID', 'surf.ID', 'deep.sequence', 'surf.sequence',\n",
       "       'percent.identity', 'alignment.length', 'bitscore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73189db8-7e2b-4c27-a216-d5bbd19539eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bc9a41-68d1-41a7-a52a-3e491a13cee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deep.ID</th>\n",
       "      <th>surf.ID</th>\n",
       "      <th>deep.sequence</th>\n",
       "      <th>surf.sequence</th>\n",
       "      <th>percent.identity</th>\n",
       "      <th>alignment.length</th>\n",
       "      <th>bitscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR7066492_k141_369890_2</td>\n",
       "      <td>SRR7066493_k141_874768_2</td>\n",
       "      <td>MTENERKFTLVGLGEILWDVLPDGKQLGGAPANFAYHAQALGGRGI...</td>\n",
       "      <td>MTERGKYVCVGLGEILWDMLPEGKQLGGAPANFAYHAQALRGQGVV...</td>\n",
       "      <td>70.7</td>\n",
       "      <td>256</td>\n",
       "      <td>360.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR7066492_k141_369890_2</td>\n",
       "      <td>SRR7066493_k141_1284874_2</td>\n",
       "      <td>MTENERKFTLVGLGEILWDVLPDGKQLGGAPANFAYHAQALGGRGI...</td>\n",
       "      <td>MTVDGKYLCVGLGEILWDMLPGGKQLGGAPANFAYHSQALGAQGVV...</td>\n",
       "      <td>70.4</td>\n",
       "      <td>250</td>\n",
       "      <td>355.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR7066492_k141_443867_2</td>\n",
       "      <td>SRR7066493_k141_1612491_4</td>\n",
       "      <td>MKVALLGLLQSGKSSIFAGLSGKSIPPVGSTAIEEAIVPVPDERLD...</td>\n",
       "      <td>MKVALVGLLQSGKSTILASLSGKAIPAIGSASIEEAIVSVPDDRFD...</td>\n",
       "      <td>78.4</td>\n",
       "      <td>356</td>\n",
       "      <td>559.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR7066492_k141_443867_2</td>\n",
       "      <td>SRR7066493_k141_1619980_3</td>\n",
       "      <td>MKVALLGLLQSGKSSIFAGLSGKSIPPVGSTAIEEAIVPVPDERLD...</td>\n",
       "      <td>MKVALIGLLQSGKSTILASLTGKAIPAIGSASIEETIVPVPDERFD...</td>\n",
       "      <td>78.1</td>\n",
       "      <td>356</td>\n",
       "      <td>555.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR7066492_k141_443867_2</td>\n",
       "      <td>SRR7066493_k141_1671894_1</td>\n",
       "      <td>MKVALLGLLQSGKSSIFAGLSGKSIPPVGSTAIEEAIVPVPDERLD...</td>\n",
       "      <td>MKVALIGLLQSGKSTILASLTGKAVPAAGSASIEEAIVPVPDERFD...</td>\n",
       "      <td>77.5</td>\n",
       "      <td>356</td>\n",
       "      <td>550.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>SRR7066492_k141_666341_2</td>\n",
       "      <td>SRR7066493_k141_242132_1</td>\n",
       "      <td>MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...</td>\n",
       "      <td>MGQKEGVILIVDDERDHADGLAESLEKLCARAIAVYDGTDALQILR...</td>\n",
       "      <td>75.1</td>\n",
       "      <td>370</td>\n",
       "      <td>548.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>SRR7066492_k141_666341_2</td>\n",
       "      <td>SRR7066493_k141_1618303_2</td>\n",
       "      <td>MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...</td>\n",
       "      <td>MAQKAGVILVVDDERDHADGIVESLEKLCTQAIAVYNGTDALEIVR...</td>\n",
       "      <td>74.7</td>\n",
       "      <td>367</td>\n",
       "      <td>538.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>SRR7066492_k141_666341_2</td>\n",
       "      <td>SRR7066493_k141_1439149_3</td>\n",
       "      <td>MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...</td>\n",
       "      <td>MKQKANIILVVDDERDHADGIAEALEKLCTKAIAVYTGKDALEIVR...</td>\n",
       "      <td>73.8</td>\n",
       "      <td>370</td>\n",
       "      <td>535.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>SRR7066492_k141_666341_2</td>\n",
       "      <td>SRR7066493_k141_1723797_3</td>\n",
       "      <td>MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...</td>\n",
       "      <td>MAQKAGVILVVDDERDHADGIVESLEKLCTRAIAVYNGTDAMEIVR...</td>\n",
       "      <td>74.7</td>\n",
       "      <td>367</td>\n",
       "      <td>532.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>SRR7066492_k141_666341_2</td>\n",
       "      <td>SRR7066493_k141_301061_2</td>\n",
       "      <td>MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...</td>\n",
       "      <td>MRSRQIDVIVTDLKLGGDIDGLAILEEAKKFNDSTEVILITAYGTI...</td>\n",
       "      <td>75.1</td>\n",
       "      <td>329</td>\n",
       "      <td>479.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       deep.ID                    surf.ID  \\\n",
       "0     SRR7066492_k141_369890_2   SRR7066493_k141_874768_2   \n",
       "1     SRR7066492_k141_369890_2  SRR7066493_k141_1284874_2   \n",
       "2     SRR7066492_k141_443867_2  SRR7066493_k141_1612491_4   \n",
       "3     SRR7066492_k141_443867_2  SRR7066493_k141_1619980_3   \n",
       "4     SRR7066492_k141_443867_2  SRR7066493_k141_1671894_1   \n",
       "...                        ...                        ...   \n",
       "4995  SRR7066492_k141_666341_2   SRR7066493_k141_242132_1   \n",
       "4996  SRR7066492_k141_666341_2  SRR7066493_k141_1618303_2   \n",
       "4997  SRR7066492_k141_666341_2  SRR7066493_k141_1439149_3   \n",
       "4998  SRR7066492_k141_666341_2  SRR7066493_k141_1723797_3   \n",
       "4999  SRR7066492_k141_666341_2   SRR7066493_k141_301061_2   \n",
       "\n",
       "                                          deep.sequence  \\\n",
       "0     MTENERKFTLVGLGEILWDVLPDGKQLGGAPANFAYHAQALGGRGI...   \n",
       "1     MTENERKFTLVGLGEILWDVLPDGKQLGGAPANFAYHAQALGGRGI...   \n",
       "2     MKVALLGLLQSGKSSIFAGLSGKSIPPVGSTAIEEAIVPVPDERLD...   \n",
       "3     MKVALLGLLQSGKSSIFAGLSGKSIPPVGSTAIEEAIVPVPDERLD...   \n",
       "4     MKVALLGLLQSGKSSIFAGLSGKSIPPVGSTAIEEAIVPVPDERLD...   \n",
       "...                                                 ...   \n",
       "4995  MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...   \n",
       "4996  MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...   \n",
       "4997  MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...   \n",
       "4998  MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...   \n",
       "4999  MDKDTVILVVDDEREHADGIAEAMEKLCGRAIAVYNGADALEIVRN...   \n",
       "\n",
       "                                          surf.sequence  percent.identity  \\\n",
       "0     MTERGKYVCVGLGEILWDMLPEGKQLGGAPANFAYHAQALRGQGVV...              70.7   \n",
       "1     MTVDGKYLCVGLGEILWDMLPGGKQLGGAPANFAYHSQALGAQGVV...              70.4   \n",
       "2     MKVALVGLLQSGKSTILASLSGKAIPAIGSASIEEAIVSVPDDRFD...              78.4   \n",
       "3     MKVALIGLLQSGKSTILASLTGKAIPAIGSASIEETIVPVPDERFD...              78.1   \n",
       "4     MKVALIGLLQSGKSTILASLTGKAVPAAGSASIEEAIVPVPDERFD...              77.5   \n",
       "...                                                 ...               ...   \n",
       "4995  MGQKEGVILIVDDERDHADGLAESLEKLCARAIAVYDGTDALQILR...              75.1   \n",
       "4996  MAQKAGVILVVDDERDHADGIVESLEKLCTQAIAVYNGTDALEIVR...              74.7   \n",
       "4997  MKQKANIILVVDDERDHADGIAEALEKLCTKAIAVYTGKDALEIVR...              73.8   \n",
       "4998  MAQKAGVILVVDDERDHADGIVESLEKLCTRAIAVYNGTDAMEIVR...              74.7   \n",
       "4999  MRSRQIDVIVTDLKLGGDIDGLAILEEAKKFNDSTEVILITAYGTI...              75.1   \n",
       "\n",
       "      alignment.length  bitscore  \n",
       "0                  256     360.1  \n",
       "1                  250     355.1  \n",
       "2                  356     559.3  \n",
       "3                  356     555.1  \n",
       "4                  356     550.4  \n",
       "...                ...       ...  \n",
       "4995               370     548.1  \n",
       "4996               367     538.1  \n",
       "4997               370     535.4  \n",
       "4998               367     532.7  \n",
       "4999               329     479.6  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136cbc8a-2dfa-4b06-a0d5-ed52d79c9cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1234)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e387ca58-4ab5-477a-85bd-25b8c2df5cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1746443/2754027275.py:20: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  classification_df_train = pd.DataFrame({'text' : surf_series_train.append(deep_series_train, ignore_index=True), 'label' : [0]*surf_series_train.size+[1]*deep_series_train.size})\n",
      "/tmp/ipykernel_1746443/2754027275.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  classification_df_val = pd.DataFrame({'text' : surf_series_val.append(deep_series_val, ignore_index=True), 'label' : [0]*surf_series_val.size+[1]*deep_series_val.size})\n",
      "/tmp/ipykernel_1746443/2754027275.py:22: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  classification_df_test = pd.DataFrame({'text' : surf_series_test.append(deep_series_test, ignore_index=True), 'label' : [0]*surf_series_test.size+[1]*deep_series_test.size})\n"
     ]
    }
   ],
   "source": [
    "# Load one split:\n",
    "#split_no = 1\n",
    "#inds = pickle.load(open('./splits/splits.pkl', 'rb'))\n",
    "\n",
    "#for train_inds, test_inds in inds[split_no]:\n",
    "#    train_set = df.iloc[train_inds,:]\n",
    "#    test_set = df.iloc[test_inds,:]\n",
    "    \n",
    "#    train_seqs_list = train_set['surf.sequence'].tolist() + train_set['deep.sequence'].tolist()\n",
    "#    train_seqs_labels = np.concatenate([np.zeros(train_set.shape[0]), np.ones(train_set.shape[0])])\n",
    "surf_series_train = df_train['surf.sequence']\n",
    "deep_series_train = df_train['deep.sequence']\n",
    "\n",
    "surf_series_val = df_val['surf.sequence']\n",
    "deep_series_val = df_val['deep.sequence']\n",
    "\n",
    "surf_series_test = df_test['surf.sequence']\n",
    "deep_series_test = df_test['deep.sequence']\n",
    "\n",
    "classification_df_train = pd.DataFrame({'text' : surf_series_train.append(deep_series_train, ignore_index=True), 'label' : [0]*surf_series_train.size+[1]*deep_series_train.size})\n",
    "classification_df_val = pd.DataFrame({'text' : surf_series_val.append(deep_series_val, ignore_index=True), 'label' : [0]*surf_series_val.size+[1]*deep_series_val.size})\n",
    "classification_df_test = pd.DataFrame({'text' : surf_series_test.append(deep_series_test, ignore_index=True), 'label' : [0]*surf_series_test.size+[1]*deep_series_test.size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "574e2122-fecd-4635-8d49-282fdc52a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_sequence(seq, word_length, overlap):\n",
    "    if overlap >= word_length:\n",
    "        print('Overlap must be less than word length')\n",
    "        return\n",
    "    \n",
    "    for i in range(0, len(seq)-overlap, word_length-overlap):\n",
    "        yield seq[i:i+word_length]\n",
    "        \n",
    "def get_overlap_array(seq, word_length=5, overlap=2):\n",
    "    return np.array(list(overlap_sequence(seq, word_length, overlap)))\n",
    "\n",
    "def get_overlap_string(seq, word_length=5, overlap=2):\n",
    "    return ' '.join(list(overlap_sequence(seq, word_length, overlap)))\n",
    "\n",
    "def compute_metrics(epred):\n",
    "    # Computes metrics from specialized output from huggingface\n",
    "\n",
    "    preds = np.exp(epred[0]) / np.sum(np.exp(epred[0]), axis = 0)\n",
    "    labels = epred[1]\n",
    "\n",
    "    metrics = {}\n",
    "    metrics['auprc'] = average_precision_score(labels, preds[:,1])\n",
    "    metrics['auroc'] = roc_auc_score(labels, preds[:,1])\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da21cec2-b957-40eb-bd9d-06c44d9c4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df_train['text'] = classification_df_train['text'].transform(get_overlap_string)\n",
    "classification_df_val['text'] = classification_df_val['text'].transform(get_overlap_string)\n",
    "classification_df_test['text'] = classification_df_test['text'].transform(get_overlap_string)\n",
    "med_len = int(np.median([len(elem) for elem in classification_df_train['text']]))\n",
    "#classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "120a7b6a-d253-4c4e-99ac-0daaf1816d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.from_pandas(classification_df_train)\n",
    "ds_val = Dataset.from_pandas(classification_df_val)\n",
    "ds_test = Dataset.from_pandas(classification_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b75e004-d078-4598-9fbc-67568a4bc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('tokenizers/AA-overlap-5_2', model_max_length=med_len, padding_side='left', truncation_side='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfbd6ac1-66f5-4bf7-8a58-a26711d6523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds_train = ds_train.map(lambda d : tokenizer(d['text'], truncation=True, padding=True), batched=True)\n",
    "tokenized_ds_val = ds_val.map(lambda d : tokenizer(d['text'], truncation=True, padding=True), batched=True)\n",
    "tokenized_ds_test = ds_test.map(lambda d : tokenizer(d['text'], truncation=True, padding=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78962809-17bb-4edf-ba4f-6fc79928083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_splits = tokenized_ds.train_test_split(test_size=0.2)\n",
    "\n",
    "#tmp = init_splits['train']\n",
    "#test_ds = init_splits['test']\n",
    "\n",
    "#splits = tmp.train_test_split(test_size=0.1)\n",
    "#train_ds = splits['train']\n",
    "#val_ds = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "019674c0-3f57-4fa2-b484-521e2f69fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('./test-models/BERT-random/checkpoint-14500', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc7cd854-eb14-40a2-a4b2-7a41c0f4768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/custom-model-overlap-5_2',\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds_train,\n",
    "    eval_dataset=tokenized_ds_val,\n",
    "    tokenizer=tokenizer,\n",
    "    #data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7825018a-ef65-4faf-9a32-5eaed5c54854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, token_type_ids. If text, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1440\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n",
      "  Number of trainable parameters = 66955010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 07:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45, training_loss=0.7039848327636719, metrics={'train_runtime': 467.4491, 'train_samples_per_second': 3.081, 'train_steps_per_second': 0.096, 'total_flos': 128907337317120.0, 'train_loss': 0.7039848327636719, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49682485-3ff0-4440-9c18-84086a87e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, token_type_ids. If text, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 160\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6937559843063354,\n",
       " 'eval_runtime': 11.2259,\n",
       " 'eval_samples_per_second': 14.253,\n",
       " 'eval_steps_per_second': 0.445,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6660294b-8579-48d4-bf54-14762927eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, token_type_ids. If text, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 400\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "out = trainer.predict(test_dataset=tokenized_ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3be8e1ed-66cb-478f-8729-f1d3c93cdccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auprc': 0.5157264109458364, 'auroc': 0.514775}\n"
     ]
    }
   ],
   "source": [
    "scores = compute_metrics(out)\n",
    "with open('./results/BERT-custom-5_2-scores.txt','w') as data: \n",
    "      data.write(str(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cb22c1e-3899-4beb-9265-4aa23447147e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6060;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir './models/custom-model-overlap-5_2' --port=6060"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
